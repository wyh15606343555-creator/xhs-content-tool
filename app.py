"""
å°çº¢ä¹¦å†…å®¹æ™ºèƒ½å¤„ç†å·¥å…· - Demo v2.0
ä¸€é”®ç²˜è´´ â†’ è‡ªåŠ¨æå– â†’ DeepSeekæ”¹å†™ â†’ Geminiå›¾ç‰‡é‡ç»˜ â†’ æ‰“åŒ…ä¸‹è½½
"""

import streamlit as st
import requests
import json
import re
import io
import zipfile
import time
import random
from datetime import datetime
from PIL import Image

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  é¡µé¢é…ç½®
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.set_page_config(
    page_title="å°çº¢ä¹¦å†…å®¹å·¥å…· - Demo",
    page_icon="ğŸ“±",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.markdown("""<style>
.block-container { padding-top: 1.5rem; }
div.stButton > button[kind="primary"] {
    background-color: #ff2442;
    border: none;
}
div.stButton > button[kind="primary"]:hover {
    background-color: #e6203c;
    border: none;
}
.step-num {
    display: inline-block;
    background: #ff2442;
    color: white;
    width: 28px; height: 28px;
    border-radius: 50%;
    text-align: center;
    line-height: 28px;
    font-weight: bold;
    font-size: 14px;
    margin-right: 6px;
}
.status-ok { color: #10b981; font-weight: bold; }
.status-partial { color: #f59e0b; font-weight: bold; }
.status-fail { color: #ef4444; font-weight: bold; }
</style>""", unsafe_allow_html=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Session State
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
_DEFAULTS = dict(
    note_title="",
    note_text="",
    note_images=[],          # list[PIL.Image]
    rewrite_result="",
    edited_images=[],        # list[PIL.Image | None]
    content_ready=False,
    rewrite_done=False,
    images_done=False,
    extract_log="",          # æå–è¿‡ç¨‹æ—¥å¿—
)
for _k, _v in _DEFAULTS.items():
    if _k not in st.session_state:
        st.session_state[_k] = _v


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  å·¥å…·å‡½æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _resolve_key(user_input: str, name: str) -> str:
    """ä¼˜å…ˆçº§ï¼šç”¨æˆ·ä¾§è¾¹æ è¾“å…¥ > Streamlit Secretsï¼ˆæœ¬åœ°secrets.toml æˆ– Cloud Secretsï¼‰"""
    if user_input and user_input.strip():
        return user_input.strip()
    try:
        val = st.secrets.get(name, "")
        if val:
            return val
    except Exception:
        pass
    return ""


# â”€â”€ å¤šç»„UAè½®æ¢ â”€â”€
_USER_AGENTS = [
    # iPhone Safari
    "Mozilla/5.0 (iPhone; CPU iPhone OS 17_4 like Mac OS X) "
    "AppleWebKit/605.1.15 (KHTML, like Gecko) "
    "Version/17.4 Mobile/15E148 Safari/604.1",
    # Android Chrome
    "Mozilla/5.0 (Linux; Android 14; Pixel 8 Pro) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/121.0.6167.178 Mobile Safari/537.36",
    # å¾®ä¿¡å†…ç½®æµè§ˆå™¨
    "Mozilla/5.0 (iPhone; CPU iPhone OS 17_3_1 like Mac OS X) "
    "AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 "
    "MicroMessenger/8.0.47(0x18002f30) NetType/WIFI Language/zh_CN",
    # iPad Safari
    "Mozilla/5.0 (iPad; CPU OS 17_4 like Mac OS X) "
    "AppleWebKit/605.1.15 (KHTML, like Gecko) "
    "Version/17.4 Mobile/15E148 Safari/604.1",
]


def _make_session():
    """åˆ›å»ºä¸€ä¸ªå¸¦å®Œæ•´æµè§ˆå™¨æŒ‡çº¹çš„ requests Session"""
    s = requests.Session()
    ua = random.choice(_USER_AGENTS)
    s.headers.update({
        "User-Agent": ua,
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "none",
        "Sec-Fetch-User": "?1",
        "Cache-Control": "max-age=0",
    })
    return s


def _extract_url(raw: str) -> str:
    """ä»å°çº¢ä¹¦åˆ†äº«æ–‡æœ¬ä¸­æå–URL"""
    m = re.search(r'https?://[^\sï¼Œ,ã€!ï¼\]ã€‘]+', raw)
    return m.group(0).rstrip('.,;:!?ã€‚ï¼Œï¼›ï¼šï¼ï¼Ÿ') if m else raw.strip()


def _extract_share_title(raw: str) -> str:
    """ä»åˆ†äº«æ–‡æœ¬ä¸­æå–æ ‡é¢˜ï¼ˆURLå‰é¢çš„æ–‡å­—éƒ¨åˆ†ï¼‰"""
    m = re.search(r'https?://', raw)
    if not m:
        return ""
    before = raw[:m.start()].strip()
    # æ¸…ç†å¸¸è§å‰ç¼€/åç¼€å™ªéŸ³
    before = re.sub(r'^\d+\s*', '', before)  # å»æ‰å¼€å¤´æ•°å­—
    before = before.rstrip('.,ã€‚ï¼Œâ€¦ã€ ')
    # å¦‚æœå¤ªçŸ­å¯èƒ½åªæ˜¯å™ªéŸ³
    if len(before) < 4:
        return ""
    return before


# æ— ç”¨çš„æ ‡é¢˜ï¼ˆåªæ˜¯å°çº¢ä¹¦ç«™åï¼Œä¸æ˜¯ç¬”è®°å†…å®¹ï¼‰
_GARBAGE_TITLES = {"å°çº¢ä¹¦", "å°çº¢ä¹¦ - ä½ çš„ç”Ÿæ´»æŒ‡å—", "å‘ç° - å°çº¢ä¹¦", ""}


def _is_useful_title(t: str) -> bool:
    """åˆ¤æ–­æ ‡é¢˜æ˜¯å¦æœ‰å®é™…å†…å®¹ï¼ˆè€Œä¸æ˜¯ç½‘ç«™åç§°ï¼‰"""
    return bool(t) and t.strip() not in _GARBAGE_TITLES and len(t.strip()) > 3


# â”€â”€ å›¾ç‰‡é‡ç»˜é¢„è®¾æ¨¡å¼ â”€â”€
_IMAGE_PROMPT_PRESETS = {
    "å»é™¤æ–‡å­—æ°´å°ï¼ˆæ¨èï¼‰": (
        "Remove ALL text, titles, captions, watermarks, logos, and any overlaid "
        "text or graphics from this image completely. "
        "Reconstruct the areas behind the removed text naturally using the "
        "surrounding visual context. "
        "Do NOT change any people, faces, objects, poses, clothing, or the background. "
        "The output should look like the original clean photo without any text overlays."
    ),
    "å»æ–‡å­— + æš–è‰²è°ƒå¾®è°ƒ": (
        "Edit this image with these specific changes: "
        "1) Remove ALL text, watermarks, logos, and overlaid graphics completely. "
        "2) Adjust the overall color temperature to be slightly warmer and brighter. "
        "3) Add a subtle professional lighting enhancement. "
        "Keep all people, faces, objects, poses, and the scene exactly the same."
    ),
    "è½¬ä¸ºæ‰‹ç»˜æ’ç”»é£æ ¼": (
        "Transform this photograph into a clean, modern digital illustration: "
        "- Remove all text, watermarks, and overlaid graphics. "
        "- Convert the realistic photo into a stylized hand-drawn illustration. "
        "- Use bright, warm, inviting color palette. "
        "- Maintain the same composition, people's poses, and activities. "
        "- Style: professional fitness and wellness brand illustration."
    ),
    "æ›´æ¢äººç‰©å¤–è§‚ï¼ˆå…¨èº«é‡ç»˜ï¼‰": (
        "Replace the main person in this image with a completely different person: "
        "- Generate a new person with different facial features, hairstyle, and body build. "
        "- The new person should wear similar style athletic clothing but in different colors. "
        "- Maintain the same general pose and activity. "
        "- Remove all text, watermarks, and overlaid graphics. "
        "- Keep the background and setting unchanged. "
        "- The result must look like a natural, professional fitness photograph."
    ),
    "è‡ªå®šä¹‰æç¤ºè¯": "",
}


def try_extract_xhs(raw_input: str, progress_callback=None):
    """
    å¢å¼ºç‰ˆæå–ï¼šå¤šç­–ç•¥å°è¯•ã€‚
    è¿”å› (title, text, image_urls, log_messages)
    """
    logs = []
    url = _extract_url(raw_input)
    share_title = _extract_share_title(raw_input)

    if share_title:
        logs.append(f"ä»åˆ†äº«æ–‡æœ¬è¯†åˆ«åˆ°æ ‡é¢˜ç‰‡æ®µï¼šã€Œ{share_title[:40]}ã€")

    if not url.startswith("http"):
        logs.append("æœªæ‰¾åˆ°æœ‰æ•ˆé“¾æ¥")
        return share_title, "", [], logs

    logs.append(f"æå–åˆ°é“¾æ¥ï¼š{url}")

    # â”€â”€ ç­–ç•¥1ï¼šå¸¦å®Œæ•´æµè§ˆå™¨æŒ‡çº¹çš„Sessionè¯·æ±‚ â”€â”€
    if progress_callback:
        progress_callback(0.1, "ç­–ç•¥1ï¼šæ¨¡æ‹Ÿæ‰‹æœºæµè§ˆå™¨è®¿é—®â€¦")

    session = _make_session()
    title, text, images = "", "", []

    for attempt in range(2):
        try:
            if attempt > 0:
                session = _make_session()  # æ¢ä¸€ä¸ªUAé‡è¯•
                time.sleep(0.5)
                logs.append(f"é‡è¯•ç¬¬{attempt + 1}æ¬¡ï¼ˆæ›´æ¢æµè§ˆå™¨æŒ‡çº¹ï¼‰")

            resp = session.get(url, timeout=15, allow_redirects=True)
            final_url = resp.url
            logs.append(f"æœ€ç»ˆURLï¼š{final_url}ï¼ˆçŠ¶æ€ç  {resp.status_code}ï¼‰")

            if resp.status_code != 200:
                continue

            html = resp.text

            # æå– note_id å¤‡ç”¨
            note_id = ""
            nid = re.search(r'/(?:explore|discovery/item)/([a-f0-9]{24})', final_url)
            if nid:
                note_id = nid.group(1)
                logs.append(f"ç¬”è®°IDï¼š{note_id}")

            # â”€â”€ æ–¹æ³•Aï¼šog tags â”€â”€
            t = re.search(
                r'<meta[^>]+property="og:title"[^>]+content="([^"]*)"', html
            )
            if not t:
                t = re.search(
                    r'<meta[^>]+content="([^"]*)"[^>]+property="og:title"', html
                )
            if t:
                title = t.group(1)

            for pattern in [
                r'<meta[^>]+property="og:description"[^>]+content="([^"]*)"',
                r'<meta[^>]+name="description"[^>]+content="([^"]*)"',
                r'<meta[^>]+content="([^"]*)"[^>]+property="og:description"',
            ]:
                d = re.search(pattern, html)
                if d and len(d.group(1)) > len(text):
                    text = d.group(1)

            for m in re.finditer(
                r'<meta[^>]+property="og:image"[^>]+content="([^"]*)"', html
            ):
                img_url = m.group(1)
                if img_url and img_url not in images:
                    images.append(img_url)
            # ä¹Ÿå°è¯•åå‘å±æ€§é¡ºåº
            for m in re.finditer(
                r'<meta[^>]+content="([^"]*)"[^>]+property="og:image"', html
            ):
                img_url = m.group(1)
                if img_url and img_url not in images:
                    images.append(img_url)

            if (_is_useful_title(title) and text) or (text and len(text) > 10) or (images and len(images) > 0):
                logs.append(f"og:tags æå–æˆåŠŸ âœ“ï¼ˆæ ‡é¢˜{len(title)}å­—ï¼Œæ­£æ–‡{len(text)}å­—ï¼Œ{len(images)}å¼ å›¾ï¼‰")
                break
            elif title or text:
                logs.append(f"og:tags æœ‰éƒ¨åˆ†æ•°æ®ï¼ˆæ ‡é¢˜{len(title)}å­—ï¼Œæ­£æ–‡{len(text)}å­—ï¼Œ{len(images)}å¼ å›¾ï¼‰ï¼Œç»§ç»­å°è¯•â€¦")

            # â”€â”€ æ–¹æ³•Bï¼š__INITIAL_STATE__ â”€â”€
            state = re.search(
                r'window\.__INITIAL_STATE__\s*=\s*(\{.+?\})\s*</script>',
                html, re.DOTALL,
            )
            if state:
                raw_json = re.sub(r":\s*undefined", ": null", state.group(1))
                try:
                    data = json.loads(raw_json)
                    _note = None

                    # è·¯å¾„1ï¼ˆæ–°ç‰ˆï¼‰: noteData.data.noteData
                    nd = data.get("noteData", {})
                    nd_inner = nd.get("data", {}).get("noteData", {})
                    if nd_inner and nd_inner.get("title"):
                        _note = nd_inner

                    # è·¯å¾„1b: normalNotePreloadDataï¼ˆå¤‡ç”¨ï¼‰
                    if not _note:
                        preload = nd.get("normalNotePreloadData", {})
                        if preload and preload.get("title"):
                            _note = preload

                    # è·¯å¾„2ï¼ˆæ—§ç‰ˆï¼‰: note.noteDetailMap
                    if not _note:
                        note_map = data.get("note", {}).get("noteDetailMap", {})
                        if note_map:
                            _note = list(note_map.values())[0].get("note", {})

                    if _note and (_note.get("title") or _note.get("desc")):
                        title = _note.get("title", "") or title
                        text = _note.get("desc", "") or text
                        # æå–å›¾ç‰‡ï¼ˆå…¼å®¹å¤šç§å­—æ®µåï¼‰
                        img_list = _note.get("imageList", []) or _note.get("imagesList", [])
                        for img in img_list:
                            u = (img.get("url", "")
                                 or img.get("urlDefault", "")
                                 or img.get("urlSizeLarge", ""))
                            if u and u not in images:
                                images.append(u)
                        logs.append(
                            f"INITIAL_STATE æå–æˆåŠŸ âœ“"
                            f"ï¼ˆæ ‡é¢˜{len(title)}å­—ï¼Œæ­£æ–‡{len(text)}å­—ï¼Œ{len(images)}å¼ å›¾ï¼‰"
                        )
                        break
                    else:
                        logs.append(f"INITIAL_STATE å­˜åœ¨ä½†æœªæ‰¾åˆ°ç¬”è®°æ•°æ®ï¼ˆkeys: {list(data.keys())}ï¼‰")
                except json.JSONDecodeError:
                    logs.append("INITIAL_STATE JSONè§£æå¤±è´¥")

            # â”€â”€ æ–¹æ³•Cï¼šä»HTMLæ­£æ–‡æå–æ›´å¤šçº¿ç´¢ â”€â”€
            title_tag = re.search(r'<title[^>]*>([^<]+)</title>', html)
            if title_tag and not _is_useful_title(title):
                raw_title = title_tag.group(1).strip()
                # å»æ‰ " - å°çº¢ä¹¦" åç¼€
                raw_title = re.sub(r'\s*[-â€“â€”|]\s*å°çº¢ä¹¦.*$', '', raw_title)
                if _is_useful_title(raw_title):
                    title = raw_title
                    logs.append(f"ä» <title> æ ‡ç­¾æå–æ ‡é¢˜ï¼šã€Œ{title[:30]}ã€")
                else:
                    logs.append(f"<title> æ ‡ç­¾å†…å®¹æ— ç”¨ï¼šã€Œ{raw_title}ã€ï¼Œè·³è¿‡")

        except requests.exceptions.Timeout:
            logs.append(f"ç¬¬{attempt + 1}æ¬¡è¯·æ±‚è¶…æ—¶")
        except Exception as e:
            logs.append(f"ç¬¬{attempt + 1}æ¬¡è¯·æ±‚å¼‚å¸¸ï¼š{type(e).__name__}")

    # â”€â”€ ç­–ç•¥2ï¼šå¦‚æœç¬”è®°IDå¯ç”¨ï¼Œå°è¯•XHS web API â”€â”€
    if not title and not text and note_id:
        if progress_callback:
            progress_callback(0.5, "ç­–ç•¥2ï¼šå°è¯•APIæ¥å£â€¦")
        try:
            api_url = f"https://www.xiaohongshu.com/explore/{note_id}"
            session2 = _make_session()
            session2.headers["Referer"] = "https://www.xiaohongshu.com/"
            resp2 = session2.get(api_url, timeout=15, allow_redirects=True)
            if resp2.status_code == 200:
                html2 = resp2.text
                t2 = re.search(
                    r'<meta[^>]+property="og:title"[^>]+content="([^"]*)"', html2
                )
                if t2:
                    title = t2.group(1)
                d2 = re.search(
                    r'<meta[^>]+(?:property="og:description"|name="description")[^>]+content="([^"]*)"',
                    html2,
                )
                if d2:
                    text = d2.group(1)
                for m2 in re.finditer(
                    r'<meta[^>]+property="og:image"[^>]+content="([^"]*)"', html2
                ):
                    if m2.group(1) not in images:
                        images.append(m2.group(1))
                if title or text:
                    logs.append(f"APIç­–ç•¥æå–æˆåŠŸ âœ“")
        except Exception:
            logs.append("APIç­–ç•¥æœªæˆåŠŸ")

    # â”€â”€ æœ€ç»ˆå…œåº•ï¼šä¼˜å…ˆä½¿ç”¨åˆ†äº«æ–‡æœ¬ä¸­æ›´å®Œæ•´çš„æ ‡é¢˜ â”€â”€
    if share_title and (not _is_useful_title(title) or len(share_title) > len(title) * 2):
        logs.append(f"ä½¿ç”¨åˆ†äº«æ–‡æœ¬ä¸­çš„å®Œæ•´æ ‡é¢˜ï¼ˆä¼˜äºç½‘é¡µæ ‡é¢˜ã€Œ{title}ã€ï¼‰")
        title = share_title

    if title or text:
        logs.append(f"æœ€ç»ˆç»“æœï¼šæ ‡é¢˜{len(title)}å­—ï¼Œæ­£æ–‡{len(text)}å­—ï¼Œ{len(images)}å¼ å›¾ç‰‡")
    else:
        logs.append("æ‰€æœ‰ç­–ç•¥å‡æœªæˆåŠŸæå–åˆ°å†…å®¹")

    return title, text, images, logs


def download_image_url(url: str):
    """ä¸‹è½½å›¾ç‰‡è¿”å› PIL Image"""
    try:
        session = _make_session()
        session.headers["Referer"] = "https://www.xiaohongshu.com/"
        r = session.get(url, timeout=15)
        r.raise_for_status()
        return Image.open(io.BytesIO(r.content)).convert("RGB")
    except Exception:
        return None


def rewrite_with_deepseek(api_key: str, title: str, text: str, track: str, city: str) -> str:
    """è°ƒç”¨ DeepSeek æ”¹å†™æ–‡æ¡ˆ"""
    from openai import OpenAI

    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")

    system = f"""ä½ æ˜¯ä¸“ä¸šçš„å°çº¢ä¹¦æ–‡æ¡ˆæ”¹å†™ä¸“å®¶ã€‚

æ”¹å†™è§„åˆ™ï¼š
1. ä¿ç•™åŸæ–‡æ ¸å¿ƒå–ç‚¹å’Œä¿¡æ¯ç»“æ„
2. å®Œå…¨æ›´æ¢è¡¨è¾¾æ–¹å¼ï¼Œæ”¹å†™ç‡ > 70%
3. èµ›é“é£æ ¼ï¼š{track}
4. ä¿æŒå°çº¢ä¹¦å†™ä½œé£æ ¼ï¼ˆå£è¯­åŒ–ã€æœ‰æ„ŸæŸ“åŠ›ã€é€‚å½“ä½¿ç”¨ emojiï¼‰
5. ä¿ç•™å¹¶ä¼˜åŒ–è¯é¢˜æ ‡ç­¾ï¼ˆ#xxx#ï¼‰
6. èå…¥{city}æœ¬åœ°å…ƒç´ ï¼ˆåœ°æ ‡ã€å•†åœˆã€åŒºåŸŸåï¼‰
7. æ ‡é¢˜è¦æœ‰å¸å¼•åŠ›ï¼Œé€‚åˆå°çº¢ä¹¦æœç´¢

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
ã€æ ‡é¢˜ã€‘æ”¹å†™åçš„æ ‡é¢˜
ã€æ­£æ–‡ã€‘æ”¹å†™åçš„æ­£æ–‡"""

    resp = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": f"åŸæ ‡é¢˜ï¼š{title}\n\nåŸæ­£æ–‡ï¼š{text}"},
        ],
        temperature=0.8,
        max_tokens=2000,
    )
    return resp.choices[0].message.content


def edit_image_with_gemini(api_key: str, image: Image.Image, prompt: str):
    """è°ƒç”¨ Google Gemini API ç¼–è¾‘å›¾ç‰‡"""
    from google import genai
    from google.genai import types

    client = genai.Client(api_key=api_key)

    # ç¼©å°å›¾ç‰‡ä»¥å‡å°‘ä¼ è¾“é‡å’Œå¤„ç†æ—¶é—´
    img_copy = image.copy()
    img_copy.thumbnail((1024, 1024))

    buf = io.BytesIO()
    img_copy.save(buf, format="PNG")
    img_bytes = buf.getvalue()

    # æŒ‰ä¼˜å…ˆçº§å°è¯•å¤šä¸ªæ¨¡å‹ï¼ˆæ–° â†’ æ—§ï¼‰
    models = [
        "gemini-2.5-flash-preview-04-17",          # Gemini 2.5 Flashï¼ˆæœ€æ–°previewï¼‰
        "gemini-2.5-flash-image",                   # Gemini 2.5 Flash Image
        "gemini-2.0-flash-exp-image-generation",    # æ—§ç‰ˆfallback
    ]

    last_error = None
    for model_name in models:
        try:
            response = client.models.generate_content(
                model=model_name,
                contents=[
                    types.Part.from_bytes(data=img_bytes, mime_type="image/png"),
                    prompt,
                ],
                config=types.GenerateContentConfig(
                    response_modalities=["IMAGE", "TEXT"],
                ),
            )

            if response.candidates:
                for part in response.candidates[0].content.parts:
                    if (
                        hasattr(part, "inline_data")
                        and part.inline_data
                        and hasattr(part.inline_data, "mime_type")
                        and part.inline_data.mime_type
                        and part.inline_data.mime_type.startswith("image/")
                    ):
                        st.toast(f"ä½¿ç”¨æ¨¡å‹: {model_name}", icon="âœ…")
                        return Image.open(io.BytesIO(part.inline_data.data)).convert("RGB")
            # æœ‰å“åº”ä½†æ— å›¾ç‰‡
            last_error = f"{model_name}: è¿”å›äº†å“åº”ä½†æ— å›¾ç‰‡æ•°æ®"
        except Exception as e:
            err_msg = str(e)
            if "leaked" in err_msg.lower():
                last_error = f"{model_name}: API Keyå·²æ³„éœ²ï¼Œè¯·æ›´æ¢"
            elif "404" in err_msg:
                last_error = f"{model_name}: æ¨¡å‹ä¸å¯ç”¨"
            else:
                last_error = f"{model_name}: {err_msg[:100]}"
            continue

    # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
    if last_error:
        st.toast(f"å›¾ç‰‡é‡ç»˜å¤±è´¥: {last_error}", icon="âŒ")
    return None


def make_zip(title: str, text: str, images: list) -> io.BytesIO:
    """æ‰“åŒ…æ–‡æ¡ˆ + å›¾ç‰‡ä¸º ZIP"""
    buf = io.BytesIO()
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    with zipfile.ZipFile(buf, "w", zipfile.ZIP_DEFLATED) as zf:
        zf.writestr(f"æ–‡æ¡ˆ_{ts}.txt", f"{title}\n\n{text}".encode("utf-8"))
        for i, img in enumerate(images):
            ib = io.BytesIO()
            img.save(ib, format="JPEG", quality=95)
            zf.writestr(f"å›¾ç‰‡_{i + 1}.jpg", ib.getvalue())
    buf.seek(0)
    return buf


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ä¾§è¾¹æ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with st.sidebar:
    st.title("âš™ï¸ è®¾ç½®")

    # æ£€æµ‹ Secrets ä¸­æ˜¯å¦å·²æœ‰é…ç½®
    def _has_secret(name):
        try:
            return bool(st.secrets.get(name, ""))
        except Exception:
            return False

    _has_ds = _has_secret("DEEPSEEK_API_KEY")
    _has_gg = _has_secret("GOOGLE_API_KEY")

    _ds_input = st.text_input(
        "DeepSeek API Key",
        value="",
        type="password",
        placeholder="å·²ä»Secretsè¯»å– âœ“" if _has_ds else "è¯·è¾“å…¥DeepSeek API Key",
        help="åœ¨ Streamlit Secrets ä¸­é…ç½® DEEPSEEK_API_KEYï¼Œæˆ–ç›´æ¥ç²˜è´´åˆ°æ­¤å¤„",
    )
    deepseek_key = _resolve_key(_ds_input, "DEEPSEEK_API_KEY")

    _gg_input = st.text_input(
        "Google Gemini API Key",
        value="",
        type="password",
        placeholder="å·²ä»Secretsè¯»å– âœ“" if _has_gg else "è¯·è¾“å…¥Google API Key",
        help="åœ¨ Google AI Studio ç”Ÿæˆ â†’ ç²˜è´´åˆ°æ­¤å¤„ï¼Œæˆ–åœ¨ Streamlit Secrets ä¸­é…ç½® GOOGLE_API_KEY",
    )
    google_key = _resolve_key(_gg_input, "GOOGLE_API_KEY")

    st.divider()

    track = st.selectbox("ğŸƒ èµ›é“", ["ä¸Šé—¨ç§æ•™", "äº§åæ¢å¤", "é’å°‘å¹´ä½“è‚²ï¼ˆé•¿é«˜ï¼‰"])
    city = st.text_input("ğŸ“ åŸå¸‚", value="åŒ—äº¬")

    st.divider()

    prompt_mode = st.selectbox(
        "ğŸ¨ å›¾ç‰‡é‡ç»˜æ¨¡å¼",
        list(_IMAGE_PROMPT_PRESETS.keys()),
        index=0,
    )

    if prompt_mode == "è‡ªå®šä¹‰æç¤ºè¯":
        image_prompt = st.text_area(
            "è‡ªå®šä¹‰æç¤ºè¯",
            value="",
            height=100,
            placeholder="æè¿°ä½ æƒ³è¦çš„å›¾ç‰‡ç¼–è¾‘æ•ˆæœâ€¦",
        )
    else:
        image_prompt = _IMAGE_PROMPT_PRESETS[prompt_mode]
        with st.expander("æŸ¥çœ‹æç¤ºè¯å†…å®¹"):
            st.caption(image_prompt)

    st.divider()
    st.caption("Demo v2.0 | æŠ€æœ¯æ”¯æŒï¼šDavid")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ä¸»é¡µé¢
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.title("ğŸ“± å°çº¢ä¹¦å†…å®¹æ™ºèƒ½å¤„ç†å·¥å…·")
st.caption("ç²˜è´´åˆ†äº«æ–‡æœ¬ â†’ è‡ªåŠ¨æå– â†’ æ”¹å†™æ–‡æ¡ˆ â†’ å›¾ç‰‡é‡ç»˜ â†’ æ‰“åŒ…ä¸‹è½½")
st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ç¬¬ä¸€æ­¥ï¼šç²˜è´´å†…å®¹ï¼ˆä¸€ä¸ªæ¡†æå®šï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown(
    '<span class="step-num">1</span> <b>ç²˜è´´å°çº¢ä¹¦ç¬”è®°</b>',
    unsafe_allow_html=True,
)

st.markdown(
    "**æ“ä½œæ–¹æ³•ï¼š** åœ¨å°çº¢ä¹¦Appä¸­æ‰“å¼€ç¬”è®° â†’ ç‚¹å‡»ã€Œåˆ†äº«ã€â†’ã€Œå¤åˆ¶é“¾æ¥ã€â†’ ç²˜è´´åˆ°ä¸‹æ–¹è¾“å…¥æ¡†",
)

paste_input = st.text_area(
    "ç²˜è´´åˆ†äº«å†…å®¹",
    height=80,
    placeholder='ç›´æ¥ç²˜è´´ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ç«çˆ†çš„ä¸Šé—¨ä½“è‚²åˆ°å®¶ğŸ”¥ http://xhslink.com/xxx å¤åˆ¶åæ‰“å¼€ã€å°çº¢ä¹¦ã€‘æŸ¥çœ‹ç¬”è®°!',
    key="paste_box",
    label_visibility="collapsed",
)

col_extract, col_upload = st.columns([1, 2])
with col_extract:
    btn_extract = st.button("ğŸš€ ä¸€é”®æå–", type="primary", key="btn_extract", use_container_width=True)
with col_upload:
    extra_imgs = st.file_uploader(
        "è¡¥å……ä¸Šä¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼Œå¯å¤šé€‰ï¼‰",
        type=["jpg", "jpeg", "png", "webp"],
        accept_multiple_files=True,
        key="extra_imgs",
    )

# â”€â”€ æå–é€»è¾‘ â”€â”€
if btn_extract:
    if not paste_input.strip():
        st.warning("è¯·å…ˆç²˜è´´å°çº¢ä¹¦åˆ†äº«å†…å®¹")
    else:
        progress = st.progress(0, text="å¼€å§‹æå–â€¦")

        def _progress(pct, msg):
            progress.progress(pct, text=msg)

        title, text, img_urls, logs = try_extract_xhs(paste_input.strip(), _progress)

        progress.progress(0.7, text="ä¸‹è½½å›¾ç‰‡ä¸­â€¦")

        # ä¸‹è½½å›¾ç‰‡
        downloaded_imgs = []
        for i, u in enumerate(img_urls or []):
            progress.progress(
                0.7 + 0.25 * (i / max(len(img_urls), 1)),
                text=f"ä¸‹è½½ç¬¬ {i + 1}/{len(img_urls)} å¼ å›¾ç‰‡â€¦",
            )
            im = download_image_url(u)
            if im:
                downloaded_imgs.append(im)

        # åŠ ä¸Šç”¨æˆ·é¢å¤–ä¸Šä¼ çš„å›¾ç‰‡
        if extra_imgs:
            for f in extra_imgs:
                try:
                    downloaded_imgs.append(Image.open(f).convert("RGB"))
                except Exception:
                    pass

        progress.progress(1.0, text="æå–å®Œæˆï¼")

        # ä¿å­˜æå–æ—¥å¿—
        st.session_state.extract_log = "\n".join(logs)

        # åˆ¤æ–­ç»“æœ
        has_title = bool(title)
        has_text = bool(text)
        has_imgs = len(downloaded_imgs) > 0

        if has_title or has_text:
            st.session_state.note_title = title or ""
            st.session_state.note_text = text or ""
            st.session_state.note_images = downloaded_imgs
            st.session_state.content_ready = True
            st.session_state.rewrite_done = False
            st.session_state.images_done = False
            st.session_state.rewrite_result = ""
            st.session_state.edited_images = []

            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            parts = []
            if has_title:
                parts.append("æ ‡é¢˜ âœ“")
            if has_text:
                parts.append(f"æ­£æ–‡ âœ“ï¼ˆ{len(text)}å­—ï¼‰")
            if has_imgs:
                parts.append(f"{len(downloaded_imgs)}å¼ å›¾ç‰‡ âœ“")
            elif img_urls:
                parts.append(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼ˆ{len(img_urls)}å¼ ï¼‰")

            st.success(f"æå–æˆåŠŸï¼ {' | '.join(parts)}")

            if not has_text and has_title:
                st.info(
                    "ğŸ’¡ æ­£æ–‡æœªæå–åˆ°ï¼ˆå°çº¢ä¹¦äº‘ç«¯åçˆ¬é™åˆ¶ï¼‰ï¼Œä½†æ ‡é¢˜å·²è·å–ã€‚\n\n"
                    "**æ“ä½œæ–¹æ³•ï¼š** åœ¨å°çº¢ä¹¦Appä¸­æ‰“å¼€è¯¥ç¬”è®° â†’ é•¿æŒ‰æ­£æ–‡ â†’ å…¨é€‰ â†’ å¤åˆ¶ â†’ "
                    "ç²˜è´´åˆ°ä¸‹æ–¹ã€Œæ­£æ–‡ã€æ¡†ä¸­ â†’ ç‚¹å‡»ã€Œæ›´æ–°å†…å®¹ã€â†’ ç»§ç»­æ”¹å†™"
                )
            if not has_imgs and has_title:
                st.info(
                    "ğŸ’¡ å›¾ç‰‡æœªæå–åˆ°ï¼Œå¯åœ¨ä¸‹æ–¹ã€Œè¡¥å……/æ›¿æ¢å›¾ç‰‡ã€å¤„æ‰‹åŠ¨ä¸Šä¼ åŸå›¾ã€‚\n\n"
                    "**æ“ä½œæ–¹æ³•ï¼š** åœ¨å°çº¢ä¹¦Appä¸­é•¿æŒ‰å›¾ç‰‡ â†’ ä¿å­˜åˆ°æ‰‹æœº â†’ ä¼ åˆ°ç”µè„‘ â†’ ä¸Šä¼ "
                )

            st.rerun()
        else:
            st.error("æå–å¤±è´¥")
            st.info(
                "ğŸ’¡ **è§£å†³æ–¹æ³•ï¼š** åœ¨å°çº¢ä¹¦Appä¸­æ‰“å¼€ç¬”è®°ï¼Œ"
                "é•¿æŒ‰é€‰ä¸­æ­£æ–‡æ–‡å­— â†’ å¤åˆ¶ â†’ ç²˜è´´åˆ°ä¸‹æ–¹ã€Œè¡¥å……æ­£æ–‡ã€æ¡†ä¸­"
            )

# â”€â”€ æå–æ—¥å¿—ï¼ˆæŠ˜å æ˜¾ç¤ºï¼‰ â”€â”€
if st.session_state.extract_log:
    with st.expander("æŸ¥çœ‹æå–è¿‡ç¨‹è¯¦æƒ…", expanded=False):
        st.code(st.session_state.extract_log, language=None)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  å†…å®¹é¢„è§ˆ & è¡¥å……ç¼–è¾‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.session_state.content_ready:
    with st.expander("ğŸ“‹ å·²æå–çš„å†…å®¹ï¼ˆå¯ç¼–è¾‘è¡¥å……ï¼‰", expanded=True):
        edit_title = st.text_input(
            "æ ‡é¢˜",
            value=st.session_state.note_title,
            key="edit_title",
        )
        edit_text = st.text_area(
            "æ­£æ–‡",
            value=st.session_state.note_text,
            height=150,
            key="edit_text",
            placeholder="å¦‚æœæ­£æ–‡æœªæå–åˆ°ï¼Œä»å°çº¢ä¹¦Appä¸­å¤åˆ¶æ­£æ–‡ç²˜è´´åˆ°è¿™é‡Œâ€¦",
        )

        # è¡¥å……ä¸Šä¼ å›¾ç‰‡
        add_imgs = st.file_uploader(
            "è¡¥å……/æ›¿æ¢å›¾ç‰‡ï¼ˆå¯é€‰ï¼Œå¯å¤šé€‰ï¼‰",
            type=["jpg", "jpeg", "png", "webp"],
            accept_multiple_files=True,
            key="add_imgs",
        )

        if st.button("ğŸ’¾ æ›´æ–°å†…å®¹", key="btn_update"):
            st.session_state.note_title = edit_title.strip()
            st.session_state.note_text = edit_text.strip()
            if add_imgs:
                new_imgs = []
                for f in add_imgs:
                    try:
                        new_imgs.append(Image.open(f).convert("RGB"))
                    except Exception:
                        pass
                if new_imgs:
                    st.session_state.note_images = new_imgs
            st.session_state.rewrite_done = False
            st.session_state.images_done = False
            st.success("å†…å®¹å·²æ›´æ–°ï¼")
            st.rerun()

        # æ˜¾ç¤ºå·²æœ‰å›¾ç‰‡
        if st.session_state.note_images:
            cols = st.columns(min(len(st.session_state.note_images), 4))
            for i, img in enumerate(st.session_state.note_images):
                with cols[i % 4]:
                    st.image(img, caption=f"åŸå›¾ {i + 1}", use_container_width=True)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  ç¬¬äºŒæ­¥ï¼šAI æ–‡æ¡ˆæ”¹å†™
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.divider()
    st.markdown(
        '<span class="step-num">2</span> <b>AI æ–‡æ¡ˆæ”¹å†™ï¼ˆDeepSeekï¼‰</b>',
        unsafe_allow_html=True,
    )

    col_btn, col_tag = st.columns([1, 3])
    with col_btn:
        do_rewrite = st.button("ğŸš€ ä¸€é”®æ”¹å†™", type="primary", key="btn_rewrite")
    with col_tag:
        st.caption(f"èµ›é“ï¼š{track}ã€€|ã€€åŸå¸‚ï¼š{city}")

    if do_rewrite:
        if not st.session_state.note_title and not st.session_state.note_text:
            st.error("æ ‡é¢˜å’Œæ­£æ–‡éƒ½ä¸ºç©ºï¼Œè¯·å…ˆè¡¥å……å†…å®¹")
        elif not deepseek_key:
            st.error("è¯·åœ¨å·¦ä¾§æ å¡«å…¥ DeepSeek API Key")
        else:
            with st.spinner("DeepSeek æ­£åœ¨æ”¹å†™æ–‡æ¡ˆâ€¦ â³"):
                try:
                    result = rewrite_with_deepseek(
                        deepseek_key,
                        st.session_state.note_title,
                        st.session_state.note_text,
                        track,
                        city,
                    )
                    st.session_state.rewrite_result = result
                    st.session_state.rewrite_done = True
                    st.rerun()
                except Exception as e:
                    st.error(f"æ”¹å†™å¤±è´¥ï¼š{e}")

    if st.session_state.rewrite_done:
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**ğŸ“„ åŸæ–‡**")
            st.info(
                f"**{st.session_state.note_title}**\n\n"
                f"{st.session_state.note_text}"
            )
        with col2:
            st.markdown("**âœ¨ æ”¹å†™å**")
            st.success(st.session_state.rewrite_result)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  ç¬¬ä¸‰æ­¥ï¼šå›¾ç‰‡é‡ç»˜
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if st.session_state.rewrite_done and st.session_state.note_images:
        st.divider()
        st.markdown(
            '<span class="step-num">3</span> <b>å›¾ç‰‡æ™ºèƒ½é‡ç»˜ï¼ˆGoogle Geminiï¼‰</b>',
            unsafe_allow_html=True,
        )

        with st.expander("å½“å‰é‡ç»˜æç¤ºè¯", expanded=False):
            st.code(image_prompt, language=None)

        if st.button("ğŸ¨ ä¸€é”®é‡ç»˜å›¾ç‰‡", type="primary", key="btn_img"):
            if not google_key:
                st.error("è¯·åœ¨å·¦ä¾§æ å¡«å…¥ Google Gemini API Key")
            else:
                n = len(st.session_state.note_images)
                progress = st.progress(0, text="å‡†å¤‡é‡ç»˜â€¦")
                edited = []

                for i, img in enumerate(st.session_state.note_images):
                    progress.progress(
                        i / n,
                        text=f"æ­£åœ¨é‡ç»˜ç¬¬ {i + 1}/{n} å¼ â€¦",
                    )
                    result = edit_image_with_gemini(google_key, img, image_prompt)
                    edited.append(result)

                progress.progress(1.0, text="âœ… é‡ç»˜å®Œæˆï¼")
                st.session_state.edited_images = edited
                st.session_state.images_done = True
                st.rerun()

        if st.session_state.images_done:
            for i, (orig, edited) in enumerate(
                zip(st.session_state.note_images, st.session_state.edited_images)
            ):
                col1, col2 = st.columns(2)
                with col1:
                    st.image(orig, caption=f"åŸå›¾ {i + 1}", use_container_width=True)
                with col2:
                    if edited:
                        st.image(edited, caption=f"é‡ç»˜å {i + 1}", use_container_width=True)
                    else:
                        st.warning(f"å›¾ç‰‡ {i + 1} é‡ç»˜å¤±è´¥ï¼Œå¯å°è¯•è°ƒæ•´æç¤ºè¯é‡è¯•")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  ç¬¬å››æ­¥ï¼šæ‰“åŒ…ä¸‹è½½
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if st.session_state.rewrite_done:
        st.divider()
        st.markdown(
            '<span class="step-num">4</span> <b>æ‰“åŒ…ä¸‹è½½</b>',
            unsafe_allow_html=True,
        )

        ts = datetime.now().strftime("%Y%m%d_%H%M%S")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.download_button(
                "ğŸ“ ä¸‹è½½æ”¹å†™æ–‡æ¡ˆ",
                data=st.session_state.rewrite_result.encode("utf-8"),
                file_name=f"æ”¹å†™æ–‡æ¡ˆ_{ts}.txt",
                mime="text/plain",
            )

        with col2:
            if st.session_state.images_done:
                good_imgs = [
                    img
                    for img in st.session_state.edited_images
                    if img is not None
                ]
                if good_imgs:
                    zip_data = make_zip(
                        st.session_state.rewrite_result[:60],
                        st.session_state.rewrite_result,
                        good_imgs,
                    )
                    st.download_button(
                        "ğŸ“¦ ä¸‹è½½å…¨éƒ¨ï¼ˆZIPï¼‰",
                        data=zip_data,
                        file_name=f"å°çº¢ä¹¦å†…å®¹_{ts}.zip",
                        mime="application/zip",
                    )

        with col3:
            if st.session_state.note_images:
                zip_orig = make_zip(
                    st.session_state.rewrite_result[:60],
                    st.session_state.rewrite_result,
                    st.session_state.note_images,
                )
                st.download_button(
                    "ğŸ“¦ æ–‡æ¡ˆ+åŸå›¾ï¼ˆZIPï¼‰",
                    data=zip_orig,
                    file_name=f"æ–‡æ¡ˆåŠ åŸå›¾_{ts}.zip",
                    mime="application/zip",
                )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  é¡µè„š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.divider()
st.caption(
    "ğŸ’¡ ä½¿ç”¨æµç¨‹ï¼šå°çº¢ä¹¦App â†’ åˆ†äº« â†’ å¤åˆ¶é“¾æ¥ â†’ ç²˜è´´åˆ°ä¸Šæ–¹ â†’ ä¸€é”®æå–"
)
